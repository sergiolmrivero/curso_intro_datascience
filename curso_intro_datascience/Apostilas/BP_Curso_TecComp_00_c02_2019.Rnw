
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%    CAPITULO
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% !Rnw root = BP_Curso_TecComp_00_2019.Rnw
\SweaveOpts{concordance=TRUE, echo=FALSE, eval=TRUE}

		
\chapter{Aula 2 - Acessando e Utilizando Bases de Dados}

Apresentar o conceito de Dataframe, os tipos de dados utilizados no R e os principais comandos  

\section{O ciclo de tratamento e análise de dados}

Atividades que utilizam dados e fazem algum tratamento formal (estatístico, matemático) destes dados são comuns tanto no mundo acadêmico quanto no mundo corporativo. Muitas vezes, os dados correspondem a milhões de observações em diversas bases de dados. Estas bases de dados, muitas vezes têm estruturas complexas e diferentes formas de organização, armazenamento, codificação, mecanismos de busca, etc. Tratar e analisar estes dados exige planejamento, avaliação, organização, o que implica em uma atividade sistemática e no uso de ferramentas adequadas para a tarefa.

Um outro aspecto relevante também é que muitos dados podem ser analisados, usando técnicas, objetivos e/ou perspectivas diferentes. O que significa que os mesmos dados, coletados e tratados, podem ter um reuso para diferentes projetos e análises. Esta possibilidade de reuso torna ainda mais importante o seu tratamento e armazenamento sistematizado. 

Podemos então dizer que os dados tem um \textit{ciclo de vida} e este ciclo pode ser pensado como um conjunto de atividades que vão do planejamento de seu uso até a sua análise. Abaixo, na figura \ref{fig:f02-01}, apresentamos um exemplo de ciclo de vida que pode ser encontrado em  \url{https://www.dataone.org/data-life-cycle}


\begin{figure}[htpb]
	\centering
	\includegraphics[width=\linewidth]{../figs/BP_Curso_TecComp_00_2019_f02-01}
	\caption{O Ciclo de Tratamento e Análise de Dados}
	\label{fig:f02-01}
\end{figure}


Este ciclo de vida tem oito componentes:


O ciclo de vida dos dados DataONE possui oito componentes \footnote{\url{https://www.dataone.org/data-life-cycle}}:

\begin{itemize}
	\item Planejar: descrição dos dados que serão compilados e como os dados serão gerenciados e disponibilizados ao longo de sua vida útil
	\item Coletar: as observações são feitas manualmente, com sensores ou outros instrumentos ou os dados são adquiridos de instituições que os produzem
	\item Validar: a qualidade dos dados é assegurada por meio de verificações e checagens
	\item Descrever: os dados são descritos com precisão e detalhadamente usando os padrões de metadados apropriados
	\item Preservar: os dados são submetidos a um arquivo de longo prazo apropriado (ou seja, data center)
	\item Descobrir: dados potencialmente úteis são localizados e obtidos, juntamente com as informações relevantes sobre os dados (metadados)
	\item Integrar: dados de fontes diferentes são combinados para formar um conjunto homogêneo de dados que podem ser prontamente analisados
	\item Analisar: os dados são analisados
	
\end{itemize}

Algumas atividades de pesquisa podem usar apenas parte do ciclo de vida; por exemplo, um projeto envolvendo metanálise pode se concentrar nas etapas de Descobrir, Integrar e Analisar, enquanto um projeto focado na coleta e análise de dados primários pode ignorar as etapas de Descobrir e Integrar. Além disso, outros projetos podem não seguir o caminho linear descrito aqui, ou várias revoluções do ciclo podem ser necessárias. Além disso, alguns cientistas ou equipes (por exemplo, aqueles envolvidos em modelagem e síntese) podem criar novos dados no processo de descobrir, integrar, analisar e sintetizar os dados existentes.


\begin{figure}[htpb]
	\centering
	\includegraphics[width=\linewidth]{../figs/BP_Curso_TecComp_00_2019_f02-02}
	\caption{Tratamento de Dados Estatísticos}
	\label{fig:f02-02}
\end{figure}

Uma outra abordagem para o ciclo de vida, mais focada no tratamento de dados estatísticos para modelagem é a que podemos ter em \url{https://paulvanderlaken.com/2017/07/07/tidyverse-101-simplifying-life-for-users/}. Neste caso, estamos falando de dados já adquiridos e digitalizados de alguma forma. Então a fase de aquisição de dados é feita a partir da importação de dados já coletados. O trabalho de economistas, é, na sua maioria das vezes, feito a partir de dados secundários adquiridos de instituições de pesquisa. Neste caso, esta abordagem (Figura \ref{fig:f02-02}) é mais próxima do ciclo normalmente utilizado em análises de dados secundários.


\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.7\linewidth]{../figs/BP_Curso_TecComp_00_2019_f02-03}
	\caption{Ferramentas de Tratamento de Dados em R}
	\label{fig:f02-03}
\end{figure}

Como podemos ver na figura \ref{fig:f02-03}, temos muitos pacotes para cada tipo de tratamento. A lista acima não é exaustiva. Muito provavelmente há mais pacotes que são especializados para a resolução de problemas mais específicos, como o acesso a bases de dados SQL ou a geração de páginas na internet para visualização ou o acesso a arquivos JSON ou YAML. Por isso, é importante sempre avaliar quais os pacotes mais adequados para a solução do seu problema de tratamento de dados.

 O \textit{readr}, por exemplo \footnote{\url{https://cran.r-project.org/web/packages/readr/index.html}} é um pacote genérico para dados em formato matricial (\textit{retangular data}), tais como arquivos csv, tsv, fwf. Para ler arquivos \textit{xls} e \textit{xlsx} há pacotes como o \textit{readxl} e o \textit{xlsx}\footnote{\url{https://cran.r-project.org/web/packages/readxl/index.html} e \url{https://cran.r-project.org/web/packages/xlsx/index.html}}


O tratamento dos dados pode facilmente consumir a maior parte do tempo de um projeto de análise e modelagem. A existência de ferramentas que facilitem esta tarefa e reduzam o tempo despendido nela é uma ajuda que vem bem a calhar.

Há no R um conjunto de pacotes feitos especialmente para a fase de tratamento dos dados. O \textit{tydiverse} \cite{Wickham2014} permite a redução dos erros de codificação e a construção de um código mais simples, claro e eficaz, resduzindo assim o tempo necessário para o tratamento e limpeza dos dados \footnote{\url{https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html}}


O \textit{tidyverse} tem  pacotes  que fornecem funcionalidades para executar eficazmente as atividades de tratamentos e análise de dados, reduzindo o esforço de codificação e a possibilidade de erros. 

A maioria das vezes neste tipo de cenário os dados estão armazenados em formatos externos ao R e devem ser importados\footnote{por exemplo, Excel, SPSS, Spyder, Jupyter}. 

Uma segunda etapa do trabalho é garantir a correção dos dados. Para isso é necessário "limpar" e "arrumar" os dados. Nesta fase é necessário eliminar erros, inconsistências de tipos de dados, problemas de codificação e representação dos dados e, eventualmente, gerar novas variáveis a partir dos próprios dados que sejam necessárias para a análise. Este processo é cíclico e também parte da análise. Durante o processo de análise dos dados é possível que surja a necessidade de novas variáveis ou que se descubra erros ainda existentes nos dados de entrada, o que implica em sua correção. 

O processo então continua até que se tenha o modelo suficientemente eficaz e testado para que resultados significativos possam ser comunicados.


Mas uma pergunta é, o que são dados limpos? Os dados limpos têm algumas características fundamentais:

\begin{enumerate}
	\item Cada coluna da sua base de dados tem apenas um tipo de dado e corresponde a apenas uma variável;
	\item Cada linha de sua base de dados corresponde a apenas uma observação;
	\item Cada elemento da base corresponde a um dado de uma variável em uma observação. 
	\item Preferencialmente, o número de observações faltantes é mínimo.
\end{enumerate}


Alguns dos pacotes utilizados para importar dados no R são:

\begin{itemize}
	\item \textit{haven} - para importar arquivos SPSS, Stata, e SAS;
	\item \textit{readxl} e \textit{xlsx} - arquivos excel (.xls e .xlsx);
	\item \textit{DBI} - arquivos de bancos de dados;
	\item \textit{jsonlite} - arquivos \textit{json};
	\item \textit{xml2} - arquivos padrão \textit{XML}
	\item \textit{httr} - \textit{APIs} na \textit{Web}
\end{itemize}

Há um conjunto grande de pacotes em R para importação de dados. O ideal é, na fase do planejamento do tratamento dos dados, você definir qual estratégia utilizar para importar os dados para o R.


\section{Tipos de Dados em R}

Os tipos de dados do R incluem: dados escalares, vetores, matrizes, listas e quadro de dados (Dataframe).

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{../figs/BP_Curso_TecComp_00_2019_f02-04}
	\caption{Uma representação gráfica dos tipos de dados em R. \\ Fonte: \url{http://venus.ifca.unican.es/Rintro/index.html}}
	\label{fig:f02-04}
\end{figure}



\subsection{Escalares}
Determinada variável pode ser um escalar, ou seja, simplesmente um número:

Exemplo de escalares:
<<echo=TRUE>>=
a <- 2
b <- 2*a
a
b
@

\subsection{Vetores}
O vetor é um objeto matemático caracterizado em um conjunto de segmentos orientdos de reta que possuem o mesmo módulo, direção e sentido. Ele contêm elementos de classes diferentes, conforme apresentado abaixo:


Vetor de classe numérica:
<<echo=TRUE>>=
a <- c(1,3500,5.3,543,-2,4000)
@
Vetor de classe de caractér:
<<echo=TRUE>>=
b <- c("taxa de juros","taxa de câmbio","reservas bancárias") 
@
Vetor de classe lógica:
<<echo=TRUE>>=
c <- c(FALSE,TRUE,FALSE,TRUE) 
@
\subsection{Matrizes}
São compostas por linhas (valores ordenados na horizontal) representadas pela letra "m" e colunas (valores ordenados na vertical) representadas pela letra "n", onde os dados são convertidos segundo essas disposições.
<<echo=TRUE>>=
matriz <- matrix(data=1:16,nrow=4,ncol=4)
matriz
@
Onde:
       \begin{description}
       \item [data:] parâmetro que representa os dados usados para criar matriz;
       \item [nrow:] parâmetro para número de linhas;
       \item [ncol:] parâmetro para número de colunas.
       \end{description}

\subsection{Array}

O dado pode ser um \textbf{Array}. Essa estrutura de dados possui três dimensões, as linhas, as colunas e as camadas. 

Exemplo de Array:
<<echo=true>>=
cubo <- array(data = 1:27, dim=c(3,3,3))
cubo
@

       \begin{description}
       \item [data:] parâmetro que representa os dados usados para criar matriz;
       \item [dim:] parâmetro para determinar as dimensões do array, sendo \textbf{dim} um vetor;
       \end{description}

\url{https://www.statmethods.net/input/datatypes.html}

\url{https://swcarpentry.github.io/r-novice-inflammation/13-supp-data-structures/}

\url{https://www.tutorialspoint.com/r/r_data_types.htm}

\url{http://www.r-tutor.com/r-introduction/basic-data-types}

\url{https://www.cyclismo.org/tutorial/R/types.html}

\url{https://stat.ethz.ch/R-manual/R-devel/library/base/html/typeof.html}

\section{Dataframes}

Data frame é uma formatação de tabela presente no R que comporta duas dimensões. A primeira dimensão compreende as linhas(Observações) e a segunda dimensão compreende as colunas(variáveis). 

Vetor dos meses:
<<echo=true>>=
DATA <- c("ago/2018", "set/2018", "out/2018", 
          "nov/2018", "dez/2018", "jan/2019")
DATA
@

Vetor do IPCA para os respectivos meses do vetor DATA:
<<echo=true>>=
IPCA <- c(-0.09, 0.48, 0.45, -0.21, 0.15, 0.32)
IPCA
@

Vetor do Pib mensal em milhões(R\$) para os respectivos meses do vetor DATA:
<<echo=true>>=
PIBmensalMilhoes <- c(583011.3, 551215.6, 597218.7,
                      604073.9, 624464.1, 591715.7)
PIBmensalMilhoes
@

\newpage

Unimos os três vetores criados anteriormente em uma única estrutura de dados e conseguinte transformamos essa estrutura em um dataframe por meio dos comandos a baixo:
<<echo=true>>=
Dados <- data.frame(cbind(DATA, IPCA, PIBmensalMilhoes))
Dados
@



\url{https://www.tutorialspoint.com/r/r_data_frames.htm}

\url{https://www.datamentor.io/r-programming/data-frame/}

\url{http://www.r-tutor.com/r-introduction/data-frame}

\url{https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html}

\url{https://www.tutorialgateway.org/data-frame-in-r/}

\url{https://datacarpentry.org/R-ecology-lesson/02-starting-with-data.html}

\url{https://www.statmethods.net/input/importingdata.html}

\section{Acessando Arquivos no computador}

Para acessar um conjunto de documentos e manusear seus dados no R, primeiramente salve o arquivo no computador ou então obtenha os dados através da internet ou outras fontes. Importante prestar atenção quanto ao tipo de arquivo que se esta trabalhando, pois a prática de importar os dados para o R requer uma própria função a depender do tipo de arquivo, que pode ser: HTML, XML, Json, dados espaçados por TAB, linhas de arquivo de texto, HDF5, SPSS, Stata e outros, com inúmeros tutoriais disponíveis a pesquisa para mais informações, ficando este material no enfoque da apresentação de dois formatos de arquivos que são bastante utilizados: o csv e o xlsx..

\subsection{Importando arquivo CSV (Comma separated values) em R}


Ao salvar um arquivo em formato csv, execute o comando abaixo no R:

<<echo=true>>=
MyData <- read.csv(file="aux/PIB_BR_1996-2016.csv", header=TRUE, sep=",")
@

Onde:

file = Parâmetro que representa o arquivo que se vai importar no R. 

Observação: Copie e cole o arquivo ou endereço, conforme o exemplo, que vai ser lido em um quadro de dados chamado MyData

header = Parâmetro que especifica que esses dados incluem uma linha de cabeçalho.
 
 Observação: no trabalho com planilhas, a primeira linha é geralmente reservada para o cabeçalho.

sep = Parâmetro de indicativo que os dados vão ser separados, neste caso, por vírgulas, pois arquivos separados por vírgulas são mais fáceis de trabalhar.

Observação: em seu conjunto de dados evite nomes,valores ou campos com espaços em branco, pois cada palavra será interpretada como uma variável separada, o que resulta em erros relacionados ao número de elementos por linha em seu conjunto de dados. Para concatenar palavras insira . entre as palavras em vez de espaço. Nomes curtos são mais adequados em nomes mais longos. Evitar nomes que contenham símbolos como os seguintes: (\verb+$%^&*()-#?<>/|\[]{}+). Estes símbolos não poderão ser utilizados.

\section{Importando arquivo xlsx em R  }

Ao salvar um arquivo em formato xlsx, execute os comandos abaixo no R:

<<echo=true,eval=F>>=
library(xlsx)

xlsxFile = "aux/PIB_BR_1996-2016.xlsx"

myFile = read.xlsx(xlsxFile, 1, rowIndex = 1)
@

Onde:

xlsxFile = Parâmetro que representa o arquivo xlsx, objeto de pasta de trabalho ou URL para o arquivo xlsx.

o segundo parâmetro é o número da planilha que você vai importar

o parâmetro "rowIndex", indica onde você vai começar a ler o arquivo.

A documentação do pacote está em: \url{https://cran.r-project.org/web/packages/xlsx/xlsx.pdf}

\subsection{Mais informações}

Informações mais detalhadas sobre importação de dados, podem

\url{https://www.datacamp.com/community/tutorials/r-data-import-tutorial?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=1t1&utm_creative=332602034364&utm_targetid=dsa-473406573035&utm_loc_interest_ms=&utm_loc_physical_ms=1001610&gclid=Cj0KCQiA5NPjBRDDARIsAM9X1GLkgYWekNMkjHQnsTnRAzV7_gVEiwAqyW9CPisvAqFv2mNXzwarSlIaAgdZEALw_wcB}

\url{http://rprogramming.net/read-csv-in-r/}

\url{https://www.rdocumentation.org/packages/gdata/versions/2.18.0/topics/read.xls}

\url{https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.fwf.html}

\url{https://riptutorial.com/r/example/31447/importing-fixed-width-files}


\section{Acessando Bases de dados via \textit{APIs}}


APIs são abreviatura para Application Programming Interface (Interface de Programação de Aplicativos), permite à mÃ¡quina o acesso à funcionalidade do programa dentro de outro programa, realizando a açãoodo programa automaticamente, para o uso de funcionalidades e leitura de dados.


\subsection{Pacotes Obrigatórios}

O acesso a APIs em R, pode ser feito com o pacote httr \footnote{produzido po Hadley Wickham - \url{http://hadley.nz/}} atua criando chamadas de APIs e lidando com autenticação destas;

O pacote jsonlite, realiza suporte ao trabalho com dados JASON, para traduzir as estruturas de dados aninhadas do JSON em objetos R sensíveis; 

O  pacote lubridate, atua na transformação e extração de datas, funções úteis para trabalhar com datas, fusos horá¡rios e operações aritméticas com datas; 
\url{http://material.curso-r.com/lubridate/}


Para obtê-los 

\textbf{install.packages(c("httr", "jsonlite", "lubridate"))}


Carregar os pacotes

<<eval=F>>=
library(httr)
library(jsonlite)
library(lubridate)
@ 

A funcionalidade do R em transformar automaticamente as cadeias de caracteres em variáveis de fator (de utilidade estatística), opera de maneira indesejada,e deverá ser efetuada uma chamada de desligamento (que atuará somente nesta sessão e depois retornará à funcionalidade anterior quando reiniciado, o R). 

<<>>=
options(stringsAsFactors = FALSE)
@


Argumentos de consulta:
\begin{itemize}
	\item GET(): Recupera o arquivo;
	\item POST(): Adiciona um arquivo;
	\item DELETE(): Remove um arquivo;
	
\end{itemize}

\begin{enumerate}
	\item As API's possuem estruturas de solicitação, para isso uma solicitação de HTTP referente à base de dados com que será trabalhada, segue as seguintes descrições:
	\begin{enumerate}
		\item Verbo HTTP ( GET, POST, DELETE, etc.);
		\item O URL base da API;
		\item O caminho da URL ou o endpoint;
		\item Argumentos de consulta de URL (por exemplo, ?foo=bar);
		\item Cabeçalhos opcionais;
		\item Um corpo de solicitação opcional;
	\end{enumerate}
	
	\item usa-se a função download.file() para baixar um arquivo para o seu computador e trabalhar com ele mantendo salva uma cópia dos dados no seu computador).
	
	\item É necessário fazer analise a saída em um objeto R. podendo verificar O pacote que realiza suporte ao trabalho com dados JASON (para traduzir as estruturas de dados JSON em objetos R),faça a intalação do pacote jasolite.
	
	\item Em seguida use a função fromJSON() no pacote rjson para importar esses dados para um objeto data.frame."
	
	\item Com os dados em um formato data.frame, é possível limpá-los. 
	
	
\end{enumerate}

Exemplo de base de dados JASON retirada do Banco Central do Brasil:

Instala o pacote (apenas uma vez)

install.packages("jsonlite")

Comando para fazer o download

download.file("http://api.bcb.gov.br/dados/serie/bcdata.sgs.4329/dados?formato=json\&amp;dataInicial=01/01/2001","ICMS")

<<echo=T,eval=F>>=
library(jsonlite)


ICMS_json <- jsonlite::fromJSON("ICMS")

ICMS <- as.data.frame(ICMS_json)
ICMS$valor <- as.numeric(ICMS$valor)
str(ICMS)

ICMS$data <- as.Date(ICMS$data)
str(ICMS)

download.file("http://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados?formato=json&amp;dataInicial=01/01/2001","IPCA")
IPCA <- jsonlite::fromJSON("IPCA")
as.numeric(IPCA[,2])
ICMS <- ICMS[31:325,]
IPCA <- IPCA[175:469,]
IPCA <- IPCA[,2]
IPCA_new <- as.numeric(IPCA)
IPCA <- IPCA_new
IPCS_new <- NULL
data <- cbind(ICMS, IPCA)

deflator <- as.numeric(data[295,3])

VR <- (deflator/(as.numeric(data[,3])))*data[,2]

plot.ts(VR)
@

\url{https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/}

\url{https://cran.r-project.org/web/packages/httr/vignettes/api-packages.html}

\url{https://zapier.com/learn/apis/}

\url{https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/API-data-access-r/}



\section{Trabalhando com bases de dados muito grandes}

\url{http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/sql.html}

\url{https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html}

\url{https://db.rstudio.com/}

\url{http://www.columbia.edu/~sjm2186/EPIC_R/EPIC_R_BigData.pdf}

\url{https://www.rstudio.com/resources/webinars/working-with-big-data-in-r/}

\url{https://rpubs.com/msundar/large_data_analysis}






